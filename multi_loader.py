from langchain_core.document_loaders.base import BaseLoader
from langchain_community.document_loaders import (
    TextLoader,
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    UnstructuredHTMLLoader,
    UnstructuredMarkdownLoader,
)
from langchain_core.documents import Document
from datasets import load_dataset
import os


class MultiLoader(BaseLoader):
    """åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„ huggingface æ•°æ®é›†å’Œæœ¬åœ°æ–‡ä»¶"""
    def __init__(self, path: str):
        super().__init__()
        self.path = path

    def _convert_huggingface_path(self, dirname: str) -> str:
        """å°† huggingface ç¼“å­˜ç›®å½•è½¬æ¢ä¸º huggingface path"""
        return dirname.replace("___", "/").replace("---", "/")

    def _is_huggingface_path(self, filename) -> bool:
        return "___" in filename or "---" in filename or "/" in filename

    def _load_file(self, filename: str):
        """åŠ è½½ huggingface æ•°æ®æˆ–æœ¬åœ°æ–‡ä»¶"""
        # åŠ è½½ huggingface æ•°æ®
        if self._is_huggingface_path(filename):
            print(f"ğŸ˜€åŠ è½½ HuggingFace æ•°æ®é›†ï¼š{filename}")
            try:
                dataset = load_dataset(
                    filename,
                    split="train",
                    cache_dir="./data/huggingface",
                )
            except Exception as e:
                raise RuntimeError(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
            # åŠ è½½æˆ document
            docs = [
                Document(
                    page_content=record.get("positive_doc")[0].get("content"),
                    metadata={"question": record.get("question"),
                              "answer": record.get("answer"),
                              "datatype": record.get("positive_doc")[0].get("datatype"),
                              "title": record.get("positive_doc")[0].get("title")}
                ) for record in dataset
            ]
            return docs

        # åŠ è½½æœ¬åœ°æ–‡ä»¶
        path = os.path.join(self.path, filename)
        ext = os.path.splitext(path)[1].lower()
        if ext == '.txt':
            loader = TextLoader(path, encoding="utf-8")
        elif ext == '.pdf':
            loader = PyPDFLoader(path)
        elif ext == '.csv':
            loader = CSVLoader(path)
        elif ext == '.json':
            loader = JSONLoader(
                file_path=path,
                jq_schema="""
                .[] | {
                    question : .question,
                    answer : .answer,
                    content : .context
                }
                """,
                metadata_func=lambda record, metadata: {
                    "question": record.get("question"),
                    "answer": record.get("answer"),
                    "source": metadata.get("source"),
                },
                content_key="content"
            )
        elif ext == '.html':
            loader = UnstructuredHTMLLoader(path, mode="elements", strategy="fast")
        elif ext == '.md':
            loader = UnstructuredMarkdownLoader(path, strategy="fast")
        else:
            return [Document(page_content="", metadata={"source": path, "error": "unsupported file type"})]
        try:
            return loader.load()
        except Exception as e:
            return [Document(page_content="", metadata={"source": path, "error": str(e)})]

    def load(self):
        """åŠ è½½è·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶"""
        # è¯»å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å
        items = os.listdir(self.path)
        docs = []
        for item in items:
            if item == "huggingface":
                # è·å– huggingface æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ç¼“å­˜ç›®å½•
                dirs = os.listdir(os.path.join(self.path, item))
                for dirname in dirs:
                    path = self._convert_huggingface_path(dirname)
                    docs.extend(self._load_file(path))
            else:
                docs.extend(self._load_file(item))
        return docs
