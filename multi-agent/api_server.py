import asyncio

import os
os.environ["USER_AGENT"] = "my-agent-server/1.0"

import uvicorn
from pydantic import BaseModel, Field
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.responses import RedirectResponse
from langserve import add_routes
from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableLambda
from typing import List, Any
from typing_extensions import TypedDict

from agent import Agent, Receipt

class ChatRequest(BaseModel):
    query: str = Field(description="ç”¨æˆ·æé—®çš„å†…å®¹")
    thread_id: str = Field(description="ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒç”¨æˆ·", default="default_thread")

# ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆLifespanï¼‰
# FastAPI çš„æ ¸å¿ƒç‰¹æ€§ï¼šåœ¨æœåŠ¡å™¨å¯åŠ¨å‰å»ºç«‹è¿æ¥ï¼Œå…³é—­åé‡Šæ”¾è¿æ¥
agent_instance = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global agent_instance
    print("æ­£åœ¨åˆå§‹åŒ– Agent åŠæ•°æ®åº“è¿æ¥...")
    agent_instance = await Agent.create()
    print("âœ… ç³»ç»Ÿå°±ç»ªï¼Œæ•°æ®åº“å·²è¿æ¥ã€‚")

    yield

    print("æ­£åœ¨å…³é—­æ•°æ®åº“è¿æ¥...")
    if agent_instance:
        await agent_instance.aclose()
    print("ğŸ›‘ ç³»ç»Ÿå·²å…³é—­ã€‚")

app = FastAPI(
    title="AI Agent Server",
    version="1.0",
    description="åŸºäº LangGraph + PostgreSQL çš„å¼‚æ­¥æ™ºèƒ½ä½“æœåŠ¡",
    lifespan=lifespan
)

@app.get("/")
async def redirect_root():
    return RedirectResponse("/docs")

# æ¥å£ A: ç®€å•ç›´è§‚çš„è‡ªå®šä¹‰æ¥å£ (ä¾›å‰ç«¯ App/å°ç¨‹åºè°ƒç”¨)
# URL: POST http://localhost:8000/chat
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    response = await agent_instance.ainvoke(
        query=request.query,
        thread_id=request.thread_id,
    )

    if type(response) == Receipt:
        return {
            "reason": response.reason,
            "answer": response.answer,
            "source": response.source,
        }
    return {"answer": response}

class AgentInput(TypedDict):
    query: str

# æ¥å£ B: LangServe æ ‡å‡†æ¥å£ (ä¾›è°ƒè¯•ã€LangSmith æˆ–é«˜çº§æµå¼å‰ç«¯è°ƒç”¨)
# URL: http://localhost:8000/agent/playground
# æ³¨æ„ï¼šè¿™é‡Œé€šè¿‡ä¸€ä¸ª wrapper å‡½æ•°æ¥æš´éœ² Agent çš„èƒ½åŠ›
async def langserve_wrapper(inputs: AgentInput):
    # LangServe ä¼ è¿›æ¥çš„ inputs é€šå¸¸æ˜¯ {"messages": [...]}
    # æˆ‘ä»¬æå–æœ€åä¸€æ¡æ¶ˆæ¯ä½œä¸º query
    query = inputs["query"]
    # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæš‚æ—¶å†™æ­» thread_idï¼Œæˆ–è€…ä» config è·å–
    # å®é™…ç”Ÿäº§ä¸­ LangServe ä¼šé€šè¿‡ configurable ä¼ é€’ thread_id
    return await agent_instance.ainvoke(
        query=query,
        thread_id="default_thread",
)

langserve_runnable = RunnableLambda(langserve_wrapper)

add_routes(
    app,
    langserve_runnable,
    path="/agent",
)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000, loop="asyncio")
